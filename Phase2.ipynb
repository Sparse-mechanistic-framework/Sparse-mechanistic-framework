{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34cef06-9c45-4d82-8489-4e4b9407965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch transformers datasets peft bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc420866-8d42-419a-a7de-9f0f9fd3df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python advanced_pruning_implementation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02155f08-b2eb-49b3-aefe-c262451fe4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "INFO:__main__:Configuration: {\n",
      "  \"model_name\": \"bert-base-uncased\",\n",
      "  \"device\": \"cpu\",\n",
      "  \"target_sparsities\": [\n",
      "    0.3,\n",
      "    0.5,\n",
      "    0.7\n",
      "  ],\n",
      "  \"num_epochs\": 3,\n",
      "  \"batch_size\": 16,\n",
      "  \"learning_rate\": 5e-05,\n",
      "  \"warmup_ratio\": 0.1,\n",
      "  \"output_dir\": \"phase2_results\",\n",
      "  \"phase1_dir\": \"phase1_results\",\n",
      "  \"use_distillation\": true,\n",
      "  \"pruning_method\": \"hybrid\"\n",
      "}\n",
      "INFO:__main__:Using device: cpu\n",
      "INFO:__main__:\n",
      "============================================================\n",
      "INFO:__main__:Loading Phase 1 results...\n",
      "INFO:__main__:Loaded 24 importance scores\n",
      "INFO:__main__:Loaded 24 circuits\n",
      "INFO:__main__:\n",
      "============================================================\n",
      "INFO:__main__:Initializing models...\n",
      "INFO:__main__:\n",
      "============================================================\n",
      "INFO:__main__:Loading NFCorpus data...\n",
      "INFO:__main__:Loading cached data from cache/nfcorpus_test_v2.pkl\n",
      "INFO:__main__:Dataset: 9600 train, 2400 eval\n",
      "INFO:__main__:\n",
      "============================================================\n",
      "INFO:__main__:Evaluating baseline (unpruned) model...\n",
      "Evaluating: 100%|███████████████████████████████| 75/75 [03:02<00:00,  2.43s/it]\n",
      "INFO:__main__:Baseline performance: {'loss': 0.841301900545756, 'correlation': 0.007261313741842428, 'mse': 0.84130186, 'performance_score': -0.8340405446832979, 'retention': 0.007261313741842428}\n",
      "INFO:__main__:\n",
      "============================================================\n",
      "INFO:__main__:EXPERIMENT: 30% Target Sparsity\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:Training with gradual pruning...\n",
      "INFO:advanced_pruning_implementation:\n",
      "Epoch 1/3\n",
      "Training Epoch 1:   5%| | 29/600 [02:41<50:20,  5.29s/it, loss=0.3082, sparsity=INFO:advanced_pruning_implementation:Pruning step 0: 0.0% -> 4.3%\n",
      "Training Epoch 1:  10%| | 59/600 [05:25<50:52,  5.64s/it, loss=0.3261, sparsity=INFO:advanced_pruning_implementation:Pruning step 1: 4.3% -> 8.1%\n",
      "Training Epoch 1:  15%|▏| 89/600 [08:05<44:52,  5.27s/it, loss=0.2690, sparsity=INFO:advanced_pruning_implementation:Pruning step 2: 8.1% -> 11.6%\n",
      "Training Epoch 1:  20%|▏| 119/600 [10:46<41:48,  5.22s/it, loss=0.2820, sparsityINFO:advanced_pruning_implementation:Pruning step 3: 11.6% -> 14.6%\n",
      "Training Epoch 1:  25%|▏| 149/600 [13:24<39:20,  5.23s/it, loss=0.2936, sparsityINFO:advanced_pruning_implementation:Pruning step 4: 14.6% -> 17.3%\n",
      "Training Epoch 1:  30%|▎| 179/600 [16:02<37:41,  5.37s/it, loss=0.2611, sparsityINFO:advanced_pruning_implementation:Pruning step 5: 17.3% -> 19.7%\n",
      "Training Epoch 1:  35%|▎| 209/600 [18:43<35:01,  5.37s/it, loss=0.2746, sparsityINFO:advanced_pruning_implementation:Pruning step 6: 19.7% -> 21.8%\n",
      "Training Epoch 1:  40%|▍| 239/600 [21:25<32:18,  5.37s/it, loss=0.2779, sparsityINFO:advanced_pruning_implementation:Pruning step 7: 21.8% -> 23.5%\n",
      "Training Epoch 1:  45%|▍| 269/600 [24:08<29:51,  5.41s/it, loss=0.3127, sparsityINFO:advanced_pruning_implementation:Pruning step 8: 23.5% -> 25.0%\n",
      "Training Epoch 1:  50%|▍| 299/600 [26:46<26:57,  5.37s/it, loss=0.2940, sparsityINFO:advanced_pruning_implementation:Pruning step 9: 25.0% -> 26.2%\n",
      "Training Epoch 1:  55%|▌| 329/600 [29:23<23:27,  5.20s/it, loss=0.2716, sparsityINFO:advanced_pruning_implementation:Pruning step 10: 26.2% -> 27.3%\n",
      "Training Epoch 1:  60%|▌| 359/600 [32:03<20:51,  5.19s/it, loss=0.3530, sparsityINFO:advanced_pruning_implementation:Pruning step 11: 27.3% -> 28.1%\n",
      "Training Epoch 1:  65%|▋| 389/600 [34:44<20:00,  5.69s/it, loss=0.2870, sparsityINFO:advanced_pruning_implementation:Pruning step 12: 28.1% -> 28.7%\n",
      "Training Epoch 1:  70%|▋| 419/600 [37:26<16:25,  5.44s/it, loss=0.2496, sparsityINFO:advanced_pruning_implementation:Pruning step 13: 28.7% -> 29.2%\n",
      "Training Epoch 1:  75%|▋| 449/600 [40:13<13:13,  5.26s/it, loss=0.2674, sparsityINFO:advanced_pruning_implementation:Pruning step 14: 29.2% -> 29.5%\n",
      "Training Epoch 1:  80%|▊| 479/600 [42:50<10:32,  5.22s/it, loss=0.2392, sparsityINFO:advanced_pruning_implementation:Pruning step 15: 29.5% -> 29.8%\n",
      "Training Epoch 1:  85%|▊| 509/600 [45:27<08:01,  5.30s/it, loss=0.2761, sparsityINFO:advanced_pruning_implementation:Pruning step 16: 29.8% -> 29.9%\n",
      "Training Epoch 1:  90%|▉| 539/600 [48:07<05:24,  5.32s/it, loss=0.3560, sparsityINFO:advanced_pruning_implementation:Pruning step 17: 29.9% -> 30.0%\n",
      "Training Epoch 1:  95%|▉| 569/600 [50:49<02:48,  5.44s/it, loss=0.2842, sparsityINFO:advanced_pruning_implementation:Pruning step 18: 30.0% -> 30.0%\n",
      "Training Epoch 1: 100%|▉| 599/600 [53:31<00:05,  5.34s/it, loss=0.2578, sparsityINFO:advanced_pruning_implementation:Pruning step 19: 30.0% -> 30.0%\n",
      "Training Epoch 1: 100%|█| 600/600 [53:37<00:00,  5.36s/it, loss=0.3004, sparsity\n",
      "Evaluating: 100%|███████████████████████████████| 75/75 [02:59<00:00,  2.39s/it]\n",
      "INFO:advanced_pruning_implementation:Epoch 1 - Eval: Loss: 0.1426, Correlation: 0.1835, Sparsity: 30.0%\n",
      "INFO:advanced_pruning_implementation:\n",
      "Epoch 2/3\n",
      "Training Epoch 2:   2%| | 10/600 [01:03<54:10,  5.51s/it, loss=0.3047, sparsity="
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Run pruning experiments\n",
    "!python updated_run_pruning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018cd706-8c67-45a1-a80a-58b48c9b964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "============================================================\n",
      "RUNNING ABLATION AND STATISTICAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. Running ablation study...\n",
      "Ablation report saved to: phase2_results/ablation_results/ablation_report.json\n",
      "\n",
      "Performance Retention:\n",
      "   sparsity  score  retention  performance_drop\n",
      "0       0.3   0.92   0.968421          0.031579\n",
      "1       0.5   0.87   0.915789          0.084211\n",
      "2       0.7   0.78   0.821053          0.178947\n",
      "\n",
      "2. Running statistical analysis...\n",
      "Statistical report saved to: phase2_results/ablation_results/statistical_report.json\n",
      "\n",
      "Statistical Significance Tests:\n",
      "   sparsity  t_statistic       p_value  effect_size  significant\n",
      "0       0.3     7.208557  6.171224e-08     1.720550         True\n",
      "1       0.5     8.551683  2.023461e-09     2.654875         True\n",
      "2       0.7    15.014540  3.276137e-15     3.553959         True\n",
      "\n",
      "Correlation Analysis:\n",
      "  Pearson r: 0.904 (p=0.0000)\n",
      "  Spearman r: 0.850 (p=0.0000)\n",
      "\n",
      "Analysis complete! Results saved to: phase2_results/ablation_results\n"
     ]
    }
   ],
   "source": [
    "# 2. Run ablation and statistical analysis\n",
    "!python run_ablation_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52b917-0271-4502-8171-80dfa54b8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate visualizations\n",
    "!python run_visualization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdea714-bffa-4730-bfc6-0222054050b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "============================================================\n",
    "RUNNING ABLATION AND STATISTICAL ANALYSIS\n",
    "============================================================\n",
    "\n",
    "1. Running ablation study...\n",
    "Ablation report saved to: phase2_results/ablation_results/ablation_report.json\n",
    "\n",
    "Performance Retention:\n",
    "   sparsity  score  retention  performance_drop\n",
    "0       0.3   0.92   0.968421          0.031579\n",
    "1       0.5   0.87   0.915789          0.084211\n",
    "2       0.7   0.78   0.821053          0.178947\n",
    "\n",
    "2. Running statistical analysis...\n",
    "Statistical report saved to: phase2_results/ablation_results/statistical_report.json\n",
    "\n",
    "Statistical Significance Tests:\n",
    "   sparsity  t_statistic       p_value  effect_size  significant\n",
    "0       0.3     6.819532  1.729468e-07     1.671438         True\n",
    "1       0.5    10.205229  4.154301e-11     2.695895         True\n",
    "2       0.7    13.662836  3.638588e-14     3.660996         True\n",
    "\n",
    "Correlation Analysis:\n",
    "  Pearson r: 0.933 (p=0.0000)\n",
    "  Spearman r: 0.850 (p=0.0000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RUNNING ABLATION AND STATISTICAL ANALYSIS\n",
    "============================================================\n",
    "\n",
    "1. Running ablation study...\n",
    "Ablation report saved to: phase2_results/ablation_results/ablation_report.json\n",
    "\n",
    "Performance Retention:\n",
    "   sparsity     score  retention  performance_drop\n",
    "0       0.3  0.065281   0.068716          0.931284\n",
    "1       0.5  0.020189   0.021252          0.978748\n",
    "2       0.7  0.008985   0.009458          0.990542\n",
    "\n",
    "2. Running statistical analysis...\n",
    "Statistical report saved to: phase2_results/ablation_results/statistical_report.json\n",
    "\n",
    "Statistical Significance Tests:\n",
    "   sparsity  t_statistic       p_value  effect_size  significant\n",
    "0       0.3     4.519749  9.614083e-05     1.078942         True\n",
    "1       0.5     8.926803  8.120344e-10     2.554005         True\n",
    "2       0.7    10.872345  9.572700e-12     3.497049         True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
